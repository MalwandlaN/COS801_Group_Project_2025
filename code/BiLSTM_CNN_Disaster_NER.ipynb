{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Af_VWiYVUN",
        "outputId": "213bf9fc-7a59-4b2a-c559-f558439b74d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Sep  3 08:49:23 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPafSGPwjRhA",
        "outputId": "7c75ee46-c6ef-41ed-857d-f0d72d8eac2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEEVgPWeETVd",
        "outputId": "e584a1a2-ad5d-4ca0-d35a-24a4ef15dbe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.17.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tf_keras\n"
          ]
        }
      ],
      "source": [
        "#check Tensorflow version\n",
        "!pip show tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWLOdX4pnNyH",
        "outputId": "610d68f3-a3c4-4499-b6ec-6b8e4dfd217d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.15.1\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.1)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.1) (1.64.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\n",
            "Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.0\n",
            "    Uninstalling ml-dtypes-0.4.0:\n",
            "      Successfully uninstalled ml-dtypes-0.4.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.3.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "#downgrade the version of tensorflow\n",
        "!pip install --upgrade tensorflow==2.16.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0J4KXTijKLA",
        "outputId": "56d74c9f-81a6-4862-ba05-ff3c2f9f4f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP_PROJECT\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/NLP_PROJECT/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VufkHII9jrgg"
      },
      "outputs": [],
      "source": [
        "# import the necessery packages\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "#from validation import compute_f1\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional, GlobalMaxPool1D, MaxPooling1D,Flatten,concatenate\n",
        "#from prepro import readfile, createBatches,createMatrices,iterate_minibatches,addCharInformatioin,padding\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Attention #Attention lauer\n",
        "#from keras_crf import CRFModel # Conditional Random Field\n",
        "#from keras_contrib.layers import CRF\n",
        "#from tensorflow_addons.layers import CRF # tfa = Tensorflow addon\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XJlDJg1Ab4f1"
      },
      "outputs": [],
      "source": [
        "#prepro.py\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# read a text file and extract the sentences\n",
        "def readfile(filename):\n",
        "    '''\n",
        "    read file\n",
        "    return format :\n",
        "    [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]\n",
        "    '''\n",
        "    f = open(filename)\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        sentence.append([splits[0],splits[-1].replace(\"\\n\",\"\")])\n",
        "\n",
        "    if len(sentence) >0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    return sentences\n",
        "\n",
        "# Extract the casing status from the word\n",
        "def getCasing(word, caseLookup):\n",
        "    casing = 'other'\n",
        "\n",
        "    numDigits = 0\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            numDigits += 1\n",
        "\n",
        "    digitFraction = numDigits / float(len(word))\n",
        "\n",
        "    if word.isdigit(): #Is a digit\n",
        "        casing = 'numeric'\n",
        "    elif digitFraction > 0.5:\n",
        "        casing = 'mainly_numeric'\n",
        "    elif word.islower(): #All lower case\n",
        "        casing = 'allLower'\n",
        "    elif word.isupper(): #All upper case\n",
        "        casing = 'allUpper'\n",
        "    elif word[0].isupper(): #is a title, initial char upper, then all lower\n",
        "        casing = 'initialUpper'\n",
        "    elif numDigits > 0:\n",
        "        casing = 'contains_digit'\n",
        "\n",
        "\n",
        "    return caseLookup[casing]\n",
        "\n",
        "# Divide the dataset into mini-batches to be trained on the model\n",
        "def createBatches(data):\n",
        "    l = []\n",
        "    for i in data:\n",
        "        l.append(len(i[0]))\n",
        "    l = set(l)\n",
        "    batches = []\n",
        "    batch_len = []\n",
        "    z = 0\n",
        "    for i in l:\n",
        "        for batch in data:\n",
        "            if len(batch[0]) == i:\n",
        "                batches.append(batch)\n",
        "                z += 1\n",
        "        batch_len.append(z)\n",
        "    return batches,batch_len\n",
        "\n",
        "def createMatrices(sentences, pos,word2Idx, label2Idx, case2Idx,char2Idx):\n",
        "    unknownIdx = word2Idx['UNKNOWN_TOKEN']\n",
        "    paddingIdx = word2Idx['PADDING_TOKEN']\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    wordCount = 0\n",
        "    unknownWordCount = 0\n",
        "    i=0\n",
        "    for sentence in sentences:\n",
        "        wordIndices = []\n",
        "        caseIndices = []\n",
        "        charIndices = []\n",
        "        labelIndices = []\n",
        "\n",
        "        for word,char,label in sentence:\n",
        "            wordCount += 1\n",
        "            if word in word2Idx:\n",
        "                wordIdx = word2Idx[word]\n",
        "            elif word.lower() in word2Idx:\n",
        "                wordIdx = word2Idx[word.lower()]\n",
        "            else:\n",
        "                wordIdx = unknownIdx\n",
        "                unknownWordCount += 1\n",
        "            charIdx = []\n",
        "            for x in char:\n",
        "                charIdx.append(char2Idx[x])\n",
        "\n",
        "            #Get the label and map to int\n",
        "            wordIndices.append(wordIdx)\n",
        "            caseIndices.append(getCasing(word, case2Idx))\n",
        "            charIndices.append(charIdx)\n",
        "            labelIndices.append(label2Idx[label])\n",
        "\n",
        "        dataset.append([wordIndices,pos[i], caseIndices, charIndices, labelIndices])\n",
        "        i+=1\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Iterate through mini-batches\n",
        "def iterate_minibatches(dataset,batch_len):\n",
        "    start = 0\n",
        "    for i in batch_len:\n",
        "        tokens = []\n",
        "        pos=[]\n",
        "        caseing = []\n",
        "        char = []\n",
        "        labels = []\n",
        "        data = dataset[start:i]\n",
        "        start = i\n",
        "        for dt in data:\n",
        "            t,p,c,ch,l = dt\n",
        "            l = np.expand_dims(l,-1)\n",
        "            tokens.append(t)\n",
        "            pos.append(p)\n",
        "            caseing.append(c)\n",
        "            char.append(ch)\n",
        "            labels.append(l)\n",
        "        yield np.asarray(labels),np.asarray(tokens),np.asarray(pos), np.asarray(caseing),np.asarray(char)\n",
        "\n",
        "# split each word into an array of characters\n",
        "def addCharInformatioin(Sentences):\n",
        "    for i,sentence in enumerate(Sentences):\n",
        "        for j,data in enumerate(sentence):\n",
        "            chars = [c for c in data[0]]\n",
        "            Sentences[i][j] = [data[0],chars,data[1]]\n",
        "    return Sentences\n",
        "\n",
        "def padding(Sentences):\n",
        "    maxlen = 52\n",
        "    for sentence in Sentences:\n",
        "        char = sentence[3]\n",
        "        for x in char:\n",
        "            maxlen = max(maxlen,len(x))\n",
        "    for i,sentence in enumerate(Sentences):\n",
        "        Sentences[i][3] = pad_sequences(Sentences[i][3],52,padding='post')\n",
        "    return Sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Im1ZMwDYUDut"
      },
      "outputs": [],
      "source": [
        "#Read the text file\n",
        "data= readfile(\"/content/drive/MyDrive/NLP_PROJECT/data/dataset.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h0E9to_ag-5a"
      },
      "outputs": [],
      "source": [
        "# split the dataset to training set and validation set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trainSentences, testSentences = train_test_split(data, test_size=0.2, random_state=15)\n",
        "#trainSentences, validSentences = train_test_split(trainSentences, test_size=0.1, random_state=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B5DOMnphnlf",
        "outputId": "450971d2-ac51-4fcb-fcf1-97d5aae0f78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of training examples: 15364\n",
            "No. of testing examples: 3841\n"
          ]
        }
      ],
      "source": [
        "print(f\"No. of training examples: {len(trainSentences)}\")\n",
        "#print(f\"No. of training examples: {len(validSentences)}\")\n",
        "print(f\"No. of testing examples: {len(testSentences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CevBkBdzgVkO"
      },
      "outputs": [],
      "source": [
        "#ex: [['We', ['W', 'e'], 'O'],  ['pay', ['p', 'a', 'y'], 'O'],  ['for', ['f', 'o', 'r'], 'O']]\n",
        "trainSentences = addCharInformatioin(trainSentences)\n",
        "#validSentences = addCharInformatioin(validSentences)\n",
        "testSentences = addCharInformatioin(testSentences)\n",
        "#ttt#testSen = addCharInformatioin(list(test_sen[\"E\"]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dd6oYA1JRra",
        "outputId": "79a3a4c0-a3ca-4ae2-979b-0fcdd81f57d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "#read train and test datasets as a dataframe in order to extract the POS tag\n",
        "def readfile_(filename):\n",
        "    '''\n",
        "    read file\n",
        "    return format :\n",
        "    [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]\n",
        "    '''\n",
        "    f = open(filename)\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    number=1;\n",
        "    for line in f:\n",
        "        if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                number+=1\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        sentence.append([number,splits[0],splits[-1].replace(\"\\n\",\"\")])\n",
        "\n",
        "    if len(sentence) >0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    return sentences\n",
        "TrS = readfile_(\"/content/drive/MyDrive/NLP_PROJECT/data/dataset.txt\")\n",
        "#teS = readfile_(\"../data/test-all.txt\")\n",
        "import pandas as pd\n",
        "import itertools\n",
        "df = pd.DataFrame(itertools.chain.from_iterable(TrS),columns=['sentence','word','tag'])\n",
        "#df_test = pd.DataFrame(itertools.chain.from_iterable(teS),columns=['sentence','word','tag'])\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.pos_tag(df_train['word'])\n",
        "df['pos'] = pd.Series(nltk.pos_tag(df['word'])).apply(lambda x: x[1])\n",
        "#df_test['pos'] = pd.Series(nltk.pos_tag(df_test['word'])).apply(lambda x: x[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSlx_Pv4vd6F",
        "outputId": "02cc07d8-78aa-43ee-fb85-70154f502ad6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-130044eb-ad38-4798-9d13-f4c0ffa922a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Houston</td>\n",
              "      <td>B-Location</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>B-Date</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>flood</td>\n",
              "      <td>B-Floods</td>\n",
              "      <td>VBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>storm</td>\n",
              "      <td>B-NaturalHazards</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>killed</td>\n",
              "      <td>B-Death_And_Toll</td>\n",
              "      <td>VBN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-130044eb-ad38-4798-9d13-f4c0ffa922a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-130044eb-ad38-4798-9d13-f4c0ffa922a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-130044eb-ad38-4798-9d13-f4c0ffa922a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e2b9e0fb-5f43-47c2-9b02-8a3175611ef5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2b9e0fb-5f43-47c2-9b02-8a3175611ef5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e2b9e0fb-5f43-47c2-9b02-8a3175611ef5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   sentence       word               tag  pos\n",
              "0         1    Houston        B-Location  NNP\n",
              "1         1  Wednesday            B-Date  NNP\n",
              "2         1      flood          B-Floods  VBD\n",
              "3         1      storm  B-NaturalHazards   NN\n",
              "4         1     killed  B-Death_And_Toll  VBN"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rFRKTUmKHzPf",
        "outputId": "f060bba0-4a12-4477-9b11-155880b1b926"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tag</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>397102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-Location</th>\n",
              "      <td>9410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-Date</th>\n",
              "      <td>4944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NaturalHazards</th>\n",
              "      <td>4501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-Location</th>\n",
              "      <td>3123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-Date</th>\n",
              "      <td>2546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-Floods</th>\n",
              "      <td>1905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-Death_And_Toll</th>\n",
              "      <td>1368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-AffectedPopulation</th>\n",
              "      <td>1150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-InfrastructureDamage</th>\n",
              "      <td>707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-NaturalHazards</th>\n",
              "      <td>707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-Death_And_Toll</th>\n",
              "      <td>654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-CollapsedStructure</th>\n",
              "      <td>347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-Fire</th>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PowerOutage</th>\n",
              "      <td>241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-Floods</th>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-AffectedPopulation</th>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-RoadBlocked</th>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-CollapsedStructure</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-InfrastructureDamage</th>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-WaterShortage</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PowerOutage</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MissingPersons</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-WaterShortage</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-RoadBlocked</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MissingPersons</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-WaterShrotage</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-WaterShrotage</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.O</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "tag\n",
              "O                         397102\n",
              "B-Location                  9410\n",
              "B-Date                      4944\n",
              "B-NaturalHazards            4501\n",
              "I-Location                  3123\n",
              "I-Date                      2546\n",
              "B-Floods                    1905\n",
              "I-Death_And_Toll            1368\n",
              "I-AffectedPopulation        1150\n",
              "I-InfrastructureDamage       707\n",
              "I-NaturalHazards             707\n",
              "B-Death_And_Toll             654\n",
              "I-CollapsedStructure         347\n",
              "B-Fire                       242\n",
              "I-PowerOutage                241\n",
              "I-Floods                     187\n",
              "B-AffectedPopulation         161\n",
              "I-RoadBlocked                112\n",
              "B-CollapsedStructure          94\n",
              "B-InfrastructureDamage        70\n",
              "I-WaterShortage               65\n",
              "B-PowerOutage                 63\n",
              "I-MissingPersons              56\n",
              "B-WaterShortage               50\n",
              "B-RoadBlocked                 25\n",
              "B-MissingPersons              10\n",
              "I-WaterShrotage                4\n",
              "B-WaterShrotage                3\n",
              ".O                             1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# number of each class entity in the dataset\n",
        "df[\"tag\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yaETKXF_J6v7"
      },
      "outputs": [],
      "source": [
        "# Convert POS from categorical to numbers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "df['pos_code'] = LE.fit_transform(df['pos'])\n",
        "#ttt#df1['pos_code'] = LE.fit_transform(df1['POS'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-k6Z8XRT8a3u",
        "outputId": "604fb6db-44bf-4bf1-c1b5-2a09151fe264"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-30d32b9d-10b3-4f73-ade3-1d1a81afc3e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>pos</th>\n",
              "      <th>pos_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Houston</td>\n",
              "      <td>B-Location</td>\n",
              "      <td>NNP</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>B-Date</td>\n",
              "      <td>NNP</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>flood</td>\n",
              "      <td>B-Floods</td>\n",
              "      <td>VBD</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>storm</td>\n",
              "      <td>B-NaturalHazards</td>\n",
              "      <td>NN</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>killed</td>\n",
              "      <td>B-Death_And_Toll</td>\n",
              "      <td>VBN</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30d32b9d-10b3-4f73-ade3-1d1a81afc3e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30d32b9d-10b3-4f73-ade3-1d1a81afc3e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30d32b9d-10b3-4f73-ade3-1d1a81afc3e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec16c542-2701-427f-beea-cb198a3e192b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec16c542-2701-427f-beea-cb198a3e192b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec16c542-2701-427f-beea-cb198a3e192b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   sentence       word               tag  pos  pos_code\n",
              "0         1    Houston        B-Location  NNP        19\n",
              "1         1  Wednesday            B-Date  NNP        19\n",
              "2         1      flood          B-Floods  VBD        34\n",
              "3         1      storm  B-NaturalHazards   NN        18\n",
              "4         1     killed  B-Death_And_Toll  VBN        36"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m8eqBwgqS5dr"
      },
      "outputs": [],
      "source": [
        "# create a list for pos_code for each sentence\n",
        "pos_sen=df.groupby('sentence')['pos_code'].apply(list)\n",
        "#ttt#pos_sen_test=df1.groupby('sentence')['pos_code'].apply(list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wAw3VCmfkZTA"
      },
      "outputs": [],
      "source": [
        "## split pos tag feature\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trainposSentences, testposSentences = train_test_split(pos_sen, test_size=0.2, random_state=15)\n",
        "#trainposSentences, validposSentences = train_test_split(trainposSentences, test_size=0.1, random_state=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FOHeSv9SsJEd"
      },
      "outputs": [],
      "source": [
        "# start indexs from 0\n",
        "trainposSentences = trainposSentences.reset_index(drop=True)\n",
        "#validposSentences=validposSentences.reset_index(drop=True)\n",
        "testposSentences=testposSentences.reset_index(drop=True)\n",
        "#tt#testp=pos_sen_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XGR7iqRoXOit"
      },
      "outputs": [],
      "source": [
        "# :: Create a mapping for the pos ::\n",
        "POSEmbeddings = np.zeros((len(pos_sen),100))\n",
        "i=0;\n",
        "for sentence in pos_sen:\n",
        "        for c in sentence:\n",
        "            POSEmbeddings[i][c]=1\n",
        "        i+=1\n",
        "\n",
        "#POSEmbeddings_test = np.zeros((len(testp),100))\n",
        "#i=0;\n",
        "#for sentence in testp:\n",
        "#        for c in sentence:\n",
        "#            POSEmbeddings_test[i][c]=1\n",
        "#        i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uumkj-0BUUfu"
      },
      "outputs": [],
      "source": [
        "#for dataset in [trainSentences,validSentences, testSentences]:\n",
        "labelSet = set()\n",
        "words = {}\n",
        "for dataset in [trainSentences, testSentences]:\n",
        "\n",
        "    for sentence in dataset:\n",
        "        for token,char,label in sentence:\n",
        "            labelSet.add(label)\n",
        "            words[token.lower()] = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g2dVzbw6chKn"
      },
      "outputs": [],
      "source": [
        "#If we are using crf model we have to create a hotencoding\n",
        "label2Idx_ = {}\n",
        "labelSet=sorted(labelSet)\n",
        "for label in labelSet:\n",
        "    ar=np.zeros(len(labelSet))\n",
        "    ar[len(label2Idx_)]=1\n",
        "    label2Idx_[label] = ar\n",
        "\n",
        "label2Idx=label2Idx_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5yG3xlyLUZ1K"
      },
      "outputs": [],
      "source": [
        "# :: Create a mapping for the labels ::\n",
        "label2IdxS = {}\n",
        "for label in labelSet:\n",
        "    label2IdxS[label] = len(label2IdxS)\n",
        "#label2Idx=label2IdxS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1duJfCHH6fp",
        "outputId": "e366056e-b81d-4133-fd01-f064f610aabd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'.O': 0,\n",
              " 'B-AffectedPopulation': 1,\n",
              " 'B-CollapsedStructure': 2,\n",
              " 'B-Date': 3,\n",
              " 'B-Death_And_Toll': 4,\n",
              " 'B-Fire': 5,\n",
              " 'B-Floods': 6,\n",
              " 'B-InfrastructureDamage': 7,\n",
              " 'B-Location': 8,\n",
              " 'B-MissingPersons': 9,\n",
              " 'B-NaturalHazards': 10,\n",
              " 'B-PowerOutage': 11,\n",
              " 'B-RoadBlocked': 12,\n",
              " 'B-WaterShortage': 13,\n",
              " 'B-WaterShrotage': 14,\n",
              " 'I-AffectedPopulation': 15,\n",
              " 'I-CollapsedStructure': 16,\n",
              " 'I-Date': 17,\n",
              " 'I-Death_And_Toll': 18,\n",
              " 'I-Floods': 19,\n",
              " 'I-InfrastructureDamage': 20,\n",
              " 'I-Location': 21,\n",
              " 'I-MissingPersons': 22,\n",
              " 'I-NaturalHazards': 23,\n",
              " 'I-PowerOutage': 24,\n",
              " 'I-RoadBlocked': 25,\n",
              " 'I-WaterShortage': 26,\n",
              " 'I-WaterShrotage': 27,\n",
              " 'O': 28}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label2IdxS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eLrQj-76U4nM"
      },
      "outputs": [],
      "source": [
        "# :: Hard coded case lookup ::\n",
        "case2Idx = {'numeric': 0, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, 'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':7}\n",
        "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7HeIrGdNU-UU"
      },
      "outputs": [],
      "source": [
        "# :: Read in word embeddings ::\n",
        "word2Idx = {}\n",
        "wordEmbeddings = []\n",
        "# reading the word embedding file in text format\n",
        "# pre-trained word vectors using in-domain contexual training\n",
        "fEmbeddings = open(\"data/vectors.100d.txt\", encoding=\"utf-8\")#contextual embedding\n",
        "#fEmbeddings = open(\"data/glove.6B.100d.txt\", encoding=\"utf-8\")#glove embedding\n",
        "#fEmbeddings = open(\"data/Word_2_vector.txt\", encoding=\"utf-8\")#word2vec embedding\n",
        "# pre-trained word vectors from word2vec embedding\n",
        "#fEmbeddings = open(\"embeddings/GoogleNews-vectors-negative300d.bin\", 'rb')\n",
        "\n",
        "for line in fEmbeddings:\n",
        "    split = line.strip().split(\" \")\n",
        "    word = split[0].lower()\n",
        "\n",
        "    if len(word2Idx) == 0: #Add padding+unknown\n",
        "        word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
        "        vector = np.zeros(len(split)-1) #Zero vector vor 'PADDING' word\n",
        "        wordEmbeddings.append(vector)\n",
        "\n",
        "        word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
        "        vector = np.random.uniform(-0.25, 0.25, len(split)-1)\n",
        "        wordEmbeddings.append(vector)\n",
        "\n",
        "    if split[0] in words:\n",
        "        vector = np.array([float(num) for num in split[1:]])\n",
        "        wordEmbeddings.append(vector)\n",
        "        word2Idx[split[0]] = len(word2Idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tvldHnezfEXt"
      },
      "outputs": [],
      "source": [
        "#only apply it when using contextual vector\n",
        "del wordEmbeddings[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cybkvrYCZ03U",
        "outputId": "2da6404c-8342-4d27-aca5-50eb26db70a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12853, 100)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordEmbeddings=np.stack( wordEmbeddings, axis=0 )\n",
        "\n",
        "wordEmbeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aqVEhBPrVSeo"
      },
      "outputs": [],
      "source": [
        "char2Idx = {\"PADDING\":0, \"UNKNOWN\":1}\n",
        "for c in \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|“”µ\\n©‚£°\\xad،¢–’—ƒ„\":\n",
        "    char2Idx[c] = len(char2Idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HchyPIbiVjol"
      },
      "outputs": [],
      "source": [
        "train_set = padding(createMatrices(trainSentences,trainposSentences,word2Idx,  label2Idx, case2Idx,char2Idx))\n",
        "#valid_set = padding(createMatrices(validSentences,validposSentences, word2Idx, label2Idx, case2Idx,char2Idx))\n",
        "test_set = padding(createMatrices(testSentences,testposSentences, word2Idx, label2Idx, case2Idx,char2Idx))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP_zUNRRH3tz",
        "outputId": "286d267b-da26-4fb3-a9ec-d8f7b71a6ac6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[173, 91, 69, 1354, 87, 36, 33, 563, 6, 75, 204, 2, 179, 5570, 8, 2, 5347, 4],\n",
              " [9, 9, 21, 19, 37, 26, 33, 26, 31, 14, 13, 10, 14, 18, 13, 10, 18, 6],\n",
              " [0, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4],\n",
              " array([[ 4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [25, 21, 24, 24, 21, 27, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [28, 17, 27, 28, 24, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [95,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [16, 27,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [26, 27, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [20, 13, 34, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [17, 26, 27, 33, 19, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [32, 27,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [24, 13, 31, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [33, 26, 32, 21, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [32, 20, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [26, 17, 36, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [20, 13, 30, 34, 17, 31, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [21, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [32, 20, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [13, 33, 32, 33, 25, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0],\n",
              "        [65,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0]], dtype=int32),\n",
              " [array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])]]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XnQtCp0pVlkQ"
      },
      "outputs": [],
      "source": [
        "idx2Label = {v: k for k, v in label2IdxS.items()}\n",
        "#np.save(\"models/idx2Label.npy\",idx2Label)\n",
        "#np.save(\"models/word2Idx.npy\",word2Idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ReCf75_IOyB",
        "outputId": "675a92ad-873b-4ad2-b76a-46303b2bae71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '.O',\n",
              " 1: 'B-AffectedPopulation',\n",
              " 2: 'B-CollapsedStructure',\n",
              " 3: 'B-Date',\n",
              " 4: 'B-Death_And_Toll',\n",
              " 5: 'B-Fire',\n",
              " 6: 'B-Floods',\n",
              " 7: 'B-InfrastructureDamage',\n",
              " 8: 'B-Location',\n",
              " 9: 'B-MissingPersons',\n",
              " 10: 'B-NaturalHazards',\n",
              " 11: 'B-PowerOutage',\n",
              " 12: 'B-RoadBlocked',\n",
              " 13: 'B-WaterShortage',\n",
              " 14: 'B-WaterShrotage',\n",
              " 15: 'I-AffectedPopulation',\n",
              " 16: 'I-CollapsedStructure',\n",
              " 17: 'I-Date',\n",
              " 18: 'I-Death_And_Toll',\n",
              " 19: 'I-Floods',\n",
              " 20: 'I-InfrastructureDamage',\n",
              " 21: 'I-Location',\n",
              " 22: 'I-MissingPersons',\n",
              " 23: 'I-NaturalHazards',\n",
              " 24: 'I-PowerOutage',\n",
              " 25: 'I-RoadBlocked',\n",
              " 26: 'I-WaterShortage',\n",
              " 27: 'I-WaterShrotage',\n",
              " 28: 'O'}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx2Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MMfet7k8V-Ck"
      },
      "outputs": [],
      "source": [
        "train_batch,train_batch_len = createBatches(train_set)\n",
        "#valid_batch,valid_batch_len = createBatches(valid_set)\n",
        "test_batch,test_batch_len = createBatches(test_set)\n",
        "#ttt#test_batch1,test_batch_len1 = createBatches(test_set_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo_j_Uhi0dsj",
        "outputId": "ba81f49c-773b-4dd2-db5e-3ad193fc349a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.3.0\n",
            "    Uninstalling typeguard-4.3.0:\n",
            "      Successfully uninstalled typeguard-4.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.3.1 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "#package is needed to run CRF class\n",
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "klyFhsumn4dM",
        "outputId": "9db4816a-cdb6-4304-c5a2-4291a312911f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#CRF Class\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
        "\n",
        "\n",
        "class CRF(L.Layer):\n",
        "    def __init__(self,\n",
        "                 output_dim,\n",
        "                 sparse_target=True,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            output_dim (int): the number of labels to tag each temporal input.\n",
        "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
        "        Input shape:\n",
        "            (batch_size, sentence length, output_dim)\n",
        "        Output shape:\n",
        "            (batch_size, sentence length, output_dim)\n",
        "        \"\"\"\n",
        "        super(CRF, self).__init__(**kwargs)\n",
        "        self.output_dim = int(output_dim)\n",
        "        self.sparse_target = sparse_target\n",
        "        self.input_spec = L.InputSpec(min_ndim=3)\n",
        "        self.supports_masking = False\n",
        "        self.sequence_lengths = None\n",
        "        self.transitions = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        f_shape = tf.TensorShape(input_shape)\n",
        "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
        "\n",
        "        if f_shape[-1] is None:\n",
        "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
        "                             'should be defined. Found `None`.')\n",
        "        if f_shape[-1] != self.output_dim:\n",
        "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
        "                             ' shape. Use a linear layer if needed.')\n",
        "        self.input_spec = input_spec\n",
        "        self.transitions = self.add_weight(name='transitions',\n",
        "                                           shape=[self.output_dim, self.output_dim],\n",
        "                                           initializer='glorot_uniform',\n",
        "                                           trainable=True)\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Just pass the received mask from previous layer, to the next layer or\n",
        "        # manipulate it if this layer changes the shape of the input\n",
        "        return mask\n",
        "\n",
        "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
        "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
        "        if sequence_lengths is not None:\n",
        "            assert len(sequence_lengths.shape) == 2\n",
        "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
        "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
        "            assert seq_len_shape[1] == 1\n",
        "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
        "        else:\n",
        "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
        "                tf.shape(inputs)[1]\n",
        "            )\n",
        "\n",
        "        viterbi_sequence, _ = crf_decode(sequences,\n",
        "                                         self.transitions,\n",
        "                                         self.sequence_lengths)\n",
        "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
        "        return K.in_train_phase(sequences, output)\n",
        "\n",
        "    @property\n",
        "    def loss(self):\n",
        "        def crf_loss(y_true, y_pred):\n",
        "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
        "            log_likelihood, self.transitions = crf_log_likelihood(\n",
        "                y_pred,\n",
        "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
        "                self.sequence_lengths,\n",
        "                transition_params=self.transitions,\n",
        "            )\n",
        "            return tf.reduce_mean(-log_likelihood)\n",
        "        return crf_loss\n",
        "\n",
        "    @property\n",
        "    def accuracy(self):\n",
        "        def viterbi_accuracy(y_true, y_pred):\n",
        "            # -1e10 to avoid zero at sum(mask)\n",
        "            mask = K.cast(\n",
        "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
        "            shape = tf.shape(y_pred)\n",
        "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
        "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
        "            if self.sparse_target:\n",
        "                y_true = K.argmax(y_true, 2)\n",
        "            y_pred = K.cast(y_pred, 'int32')\n",
        "            y_true = K.cast(y_true, 'int32')\n",
        "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
        "            return K.sum(corrects * mask) / K.sum(mask)\n",
        "        return viterbi_accuracy\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
        "        return input_shape[:2] + (self.output_dim,)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'output_dim': self.output_dim,\n",
        "            'sparse_target': self.sparse_target,\n",
        "            'supports_masking': self.supports_masking,\n",
        "            'transitions': K.eval(self.transitions)\n",
        "        }\n",
        "        base_config = super(CRF, self).get_config()\n",
        "        return dict(base_config, **config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSPiO0DP1_4X",
        "outputId": "c1fa73f3-da44-40c8-cd84-ca11d7765d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, None, 52, 100)\n",
            "(None, None, 52, 33)\n",
            "(None, None, 52, 33)\n",
            "(None, None, 52, 34)\n",
            "(None, None, 52, 100)\n",
            "after max pooling (None, None, 1, 100)\n",
            "after global max pooling (None, None, 100)\n",
            "(None, None, 100)\n"
          ]
        }
      ],
      "source": [
        "###Character Embedding\n",
        "\n",
        "from numpy.core.fromnumeric import nonzero\n",
        "from nltk.grammar import Nonterminal\n",
        "# character embedding\n",
        "'''\n",
        "Character Embedding\n",
        "\n",
        "1. Define a list a characters (i.e. m). For example, can use alphanumeric and some special characters. For my example, English characters (52), number (10), special characters (20) and one unknown character, UNK. Total 83 characters.\n",
        "2. Transfer characters as 1-hot encoding and got a sequence for vectors. For unknown characters and blank characters, use all-zero vector to replace it. If exceeding pre-defined maximum length of characters (i.e. l), ignoring it.\n",
        "The output is 30 dimensions vector per every single character.\n",
        "3. Using 3 1D CNN layers (configurable) to learn the sequence\n",
        "'''\n",
        "\n",
        "#filters=[[3, 5, 7], [200, 300, 300], [300, 400, 400]]\n",
        "# filters=[[100, 200, 200], [200, 300, 300], [300, 400, 400]],\n",
        "#kernel_sizes=[[4, 3, 3], [5, 3, 3], [6, 3, 3]]\n",
        "#pool_sizes=[[2, 2, 2], [2, 2, 2], [2, 2, 2]]\n",
        "\n",
        "filters=[33, 33, 34]\n",
        "kernel_sizes=[4, 3, 3]\n",
        "pool_sizes=[2, 2, 2]\n",
        "padding='same'\n",
        "activation='relu'\n",
        "kernel_initializer='glorot_normal'\n",
        "dropout = 0.3\n",
        "\n",
        "# number of characters is 110: \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|“”µ\\n©‚£°\\xad،¢–’—ƒ„\n",
        "#sent_input = Input(shape=(max_len_of_sentence, ), dtype='int64')\n",
        "#embedded = Embedding(self.num_of_char, char_dimension, input_length=max_len_of_sentence)(sent_input)\n",
        "character_input=Input(shape=(None,52,),dtype='int64', name='char_input')\n",
        "# Embedding input: num_char, output vector dimension, input_length, embedding_initializer, name\n",
        "# random initialization of a lookup table with values drawn from a uniform distribution with range [-0.5, 0.5] to output a character embedding of 25 dimension\n",
        "embed_char_out=TimeDistributed(Embedding(len(char2Idx),100,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
        "#embed_char_out= Dropout(0.25)(embed_char_out)\n",
        "#for i, filter_layers in enumerate(filters):\n",
        "print(embed_char_out.shape)\n",
        "blocks=[]\n",
        "block = embed_char_out\n",
        "for i, filter_layers in enumerate(filters):\n",
        "\n",
        "            block = TimeDistributed(Conv1D(\n",
        "            filters=filters[i], kernel_size=kernel_sizes[i],\n",
        "            padding=padding, activation=activation,  kernel_initializer=kernel_initializer))(block)\n",
        "            print(block.shape)\n",
        "            blocks.append(block)\n",
        "\n",
        "block = concatenate(blocks, axis=-1)\n",
        "#for i in range(len(filters)):\n",
        "#            block = Conv1D(\n",
        "#            filters=filters[i], kernel_size=kernel_size[i],\n",
        "#            padding=padding, activation=activation, strides = 1, kernel_initializer=kernel_initializer)(embed_char_out)\n",
        "print(block.shape)\n",
        "block = Dropout(dropout)(block)\n",
        "block = TimeDistributed(MaxPooling1D(52))(block)\n",
        "print(\"after max pooling\", block.shape)\n",
        "\n",
        "block = TimeDistributed(GlobalMaxPool1D())(block)\n",
        "print(\"after global max pooling\",block.shape)\n",
        "\n",
        "char =  TimeDistributed(Flatten())(block)\n",
        "print(char.shape)\n",
        "char = Dropout(0.2)(char)\n",
        "##########\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LZ5cIoddYnim"
      },
      "outputs": [],
      "source": [
        "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
        "pos_input= Input(shape=(None,), dtype='int32', name='pos_input')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fRy4FNFfY2LL"
      },
      "outputs": [],
      "source": [
        "words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=False)(words_input)\n",
        "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input)\n",
        "pos = Embedding(output_dim=POSEmbeddings.shape[1], input_dim=POSEmbeddings.shape[0], weights=[POSEmbeddings], trainable=False)(pos_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "zjjeA1Sj2Sab",
        "outputId": "5d985bf5-8c18-4066-e7ae-ff7087da4774"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# attention layer using custom class\\nattn_output= attention(return_sequences=True)(output)\\noutput = Dropout(0.5)(attn_output)\\noutput=TimeDistributed(Flatten())(output)\\n\\nprint(output.shape)\\n'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Bidirectional LSTM with Attention Layer Training\n",
        "# Query-value attention of shap                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   e [batch_size, Tq, filters].\n",
        "# query_value_attention_seq = tf.keras.layers.Attention()([query_seq_encoding, value_seq_encoding])\n",
        "#import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Attention #Attention lauer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "#from crf import CRF\n",
        "# using Attention layer from keras\n",
        "#words_char_attention = Attention()([words,pos, char])\n",
        "#words_char_attention = Attention()([words, char])\n",
        "#print(words_char_attention.shape)\n",
        "#words_char_attention = GlobalMaxPool1D()(words_char_attention_seq)\n",
        "\n",
        "#print(words_char_attention.shape)\n",
        "\n",
        "#attn_output= TimeDistributed(Attention()(output))#using Keras defined Attention layer\n",
        "#print(output.shape)\n",
        "'''\n",
        "# attention layer using custom class\n",
        "attn_output= attention(return_sequences=True)(output)\n",
        "output = Dropout(0.5)(attn_output)\n",
        "output=TimeDistributed(Flatten())(output)\n",
        "\n",
        "print(output.shape)\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vozQRVBtYfK5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "class attention(Layer):\n",
        "\n",
        "    def _init_(self, return_sequences=True):\n",
        "        self.return_sequences = return_sequences\n",
        "        super(Attention,self)._init_()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
        "                               initializer=\"normal\")\n",
        "        print(self.W.shape())\n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
        "                               initializer=\"zeros\")\n",
        "\n",
        "        super(Attention,self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x*a\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return output\n",
        "\n",
        "        return K.sum(output, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "LmV0EQUTdip7",
        "outputId": "2722a185-a50e-47f4-c515-33299efe6e97"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\\n\\n#output = concatenate([words,pos, char, words_char_attention, casing])\\noutput = concatenate([words,pos, char, casing])  #without attention layer\\nprint(output.shape)\\noutput = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\\n\\n#attn_output = Attention()([words, char])\\noutput = Attention(use_scale=True)([output,output]) #SELF-ATTENTION LAYER\\n#print(output.shape)\\n#output = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\\n# fully connected DNN layer\\noutput = TimeDistributed(Dense(150, activation = \\'relu\\')) (output)\\n\\n# output layer\\n#output = TimeDistributed(Dense(len(label2Idx), activation=\\'softmax\\'))(output)\\noutput = TimeDistributed(Dense(len(label2Idx)))(output)\\n\\n#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\\n#model.compile(loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'], optimizer=\\'nadam\\')\\n#model.summary()\\n\\n#from crf import CRF\\ncrf_ = CRF(len(label2Idx))\\n#crf_ = CRF(len(label2Idx), sparse_target=True)\\noutput = crf_(output)\\nmodel = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\\n\\nearly_stopping=EarlyStopping(monitor=\"val_loss\", patience = 3)\\n#reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, min_lr=0.0001)\\n#opt=tf.keras.optimizers.Nadam(learning_rate=0.00001)\\n#opt=tf.keras.optimizers.SGD(learning_rate=0.001)\\n#opt=tf.keras.optimizers.Adam(learning_rate=0.001)\\nopt=tf.keras.optimizers.RMSprop(learning_rate=0.001)\\nmodel.compile(optimizer=opt, loss=crf_.loss, metrics=[crf_.accuracy])\\n#model.compile(optimizer=Adam(learning_rate=0.001), loss=crf_.loss, metrics=[crf_.accuracy])\\n#model.compile(optimizer=\\'rmsprop\\', loss=crf_.loss, metrics=[crf_.accuracy])\\n\\n#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\\n#model.compile(loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'], optimizer=Adam(learning_rate=0.001))\\n#model.summary()\\n\\n'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# concatenating the word and character embedding outputs\n",
        "'''\n",
        "#from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
        "\n",
        "#output = concatenate([words,pos, char, words_char_attention, casing])\n",
        "output = concatenate([words,pos, char, casing])  #without attention layer\n",
        "print(output.shape)\n",
        "output = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\n",
        "\n",
        "#attn_output = Attention()([words, char])\n",
        "output = Attention(use_scale=True)([output,output]) #SELF-ATTENTION LAYER\n",
        "#print(output.shape)\n",
        "#output = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\n",
        "# fully connected DNN layer\n",
        "output = TimeDistributed(Dense(150, activation = 'relu')) (output)\n",
        "\n",
        "# output layer\n",
        "#output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
        "output = TimeDistributed(Dense(len(label2Idx)))(output)\n",
        "\n",
        "#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\n",
        "#model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='nadam')\n",
        "#model.summary()\n",
        "\n",
        "#from crf import CRF\n",
        "crf_ = CRF(len(label2Idx))\n",
        "#crf_ = CRF(len(label2Idx), sparse_target=True)\n",
        "output = crf_(output)\n",
        "model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor=\"val_loss\", patience = 3)\n",
        "#reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, min_lr=0.0001)\n",
        "#opt=tf.keras.optimizers.Nadam(learning_rate=0.00001)\n",
        "#opt=tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "#opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "opt=tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "#model.compile(optimizer=Adam(learning_rate=0.001), loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "#model.compile(optimizer='rmsprop', loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "\n",
        "#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\n",
        "#model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(learning_rate=0.001))\n",
        "#model.summary()\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "xSaDcwUVotYS",
        "outputId": "16bffc56-8434-460a-cf69-5c7b0d06964d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'### new experiment...............................................................\\n# concatenating the word and character embedding outputs\\n\\n#from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\\n\\n#output = concatenate([words,pos, char, words_char_attention, casing])\\noutput = concatenate([words,pos, char, casing])  #without attention layer\\nprint(output.shape)\\noutput = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\\n\\n\\n\\n#attn_output = Attention()([words, char])\\noutput = Attention(use_scale=True)([output,output]) #SELF-ATTENTION LAYER\\n#IDCNN\\noutput = Conv1D(filters=256, kernel_size=2, activation=\\'relu\\', padding=\\'same\\',\\n                            dilation_rate=1, kernel_regularizer=\\'l2\\')(output)\\noutput = Conv1D(filters=256, kernel_size=3, activation=\\'relu\\', padding=\\'same\\',\\n                            dilation_rate=1, kernel_regularizer=\\'l2\\')(output)\\noutput= Conv1D(filters=512, kernel_size=4, activation=\\'relu\\', padding=\\'same\\',\\n                            dilation_rate=2, kernel_regularizer=\\'l2\\')(output)\\n\\n#print(output.shape)\\n#output = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\\n# fully connected DNN layer\\n#output = TimeDistributed(Dense(150, activation = \\'relu\\')) (output)\\n\\n# output layer\\n#output = TimeDistributed(Dense(len(label2Idx), activation=\\'softmax\\'))(output)\\noutput = TimeDistributed(Dense(len(label2Idx)))(output)\\n\\n#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\\n#model.compile(loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'], optimizer=\\'nadam\\')\\n#model.summary()\\n\\n#from crf import CRF\\ncrf_ = CRF(len(label2Idx))\\n#crf_ = CRF(len(label2Idx), sparse_target=True)\\noutput = crf_(output)\\nmodel = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\\n\\nearly_stopping=EarlyStopping(monitor=\"val_loss\", patience = 3)\\n#reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, min_lr=0.0001)\\n#opt=tf.keras.optimizers.Nadam(learning_rate=0.00001)\\n#opt=tf.keras.optimizers.SGD(learning_rate=0.001)\\n#opt=tf.keras.optimizers.Adam(learning_rate=0.001)\\nopt=tf.keras.optimizers.RMSprop(learning_rate=0.001)\\nmodel.compile(optimizer=opt, loss=crf_.loss, metrics=[crf_.accuracy])\\n#model.compile(optimizer=Adam(learning_rate=0.001), loss=crf_.loss, metrics=[crf_.accuracy])\\n#model.compile(optimizer=\\'rmsprop\\', loss=crf_.loss, metrics=[crf_.accuracy])\\n\\n#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\\n#model.compile(loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'], optimizer=Adam(learning_rate=0.001))\\n#model.summary()\\n'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''### new experiment...............................................................\n",
        "# concatenating the word and character embedding outputs\n",
        "\n",
        "#from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
        "\n",
        "#output = concatenate([words,pos, char, words_char_attention, casing])\n",
        "output = concatenate([words,pos, char, casing])  #without attention layer\n",
        "print(output.shape)\n",
        "output = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\n",
        "\n",
        "\n",
        "\n",
        "#attn_output = Attention()([words, char])\n",
        "output = Attention(use_scale=True)([output,output]) #SELF-ATTENTION LAYER\n",
        "#IDCNN\n",
        "output = Conv1D(filters=256, kernel_size=2, activation='relu', padding='same',\n",
        "                            dilation_rate=1, kernel_regularizer='l2')(output)\n",
        "output = Conv1D(filters=256, kernel_size=3, activation='relu', padding='same',\n",
        "                            dilation_rate=1, kernel_regularizer='l2')(output)\n",
        "output= Conv1D(filters=512, kernel_size=4, activation='relu', padding='same',\n",
        "                            dilation_rate=2, kernel_regularizer='l2')(output)\n",
        "\n",
        "#print(output.shape)\n",
        "#output = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\n",
        "# fully connected DNN layer\n",
        "#output = TimeDistributed(Dense(150, activation = 'relu')) (output)\n",
        "\n",
        "# output layer\n",
        "#output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
        "output = TimeDistributed(Dense(len(label2Idx)))(output)\n",
        "\n",
        "#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\n",
        "#model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='nadam')\n",
        "#model.summary()\n",
        "\n",
        "#from crf import CRF\n",
        "crf_ = CRF(len(label2Idx))\n",
        "#crf_ = CRF(len(label2Idx), sparse_target=True)\n",
        "output = crf_(output)\n",
        "model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor=\"val_loss\", patience = 3)\n",
        "#reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, min_lr=0.0001)\n",
        "#opt=tf.keras.optimizers.Nadam(learning_rate=0.00001)\n",
        "#opt=tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "#opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "opt=tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "#model.compile(optimizer=Adam(learning_rate=0.001), loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "#model.compile(optimizer='rmsprop', loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "\n",
        "#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\n",
        "#model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(learning_rate=0.001))\n",
        "#model.summary()\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "cvq_UVfm2TFv",
        "outputId": "ad2fcbbb-ce23-40f1-8d2e-1381be27fd8f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'####global context\\nweight_init = tf.compat.v1.truncated_normal_initializer(mean=0.0, stddev=0.02)\\nweight_regularizer = tf.keras.regularizers.L2(0.0001)\\n\\ndef conv(x, channels, kernel=4, stride=2, pad=0, pad_type=\\'zero\\', use_bias=True, sn=False, scope=\\'conv_0\\'):\\n    with tf.compat.v1.variable_scope(scope):\\n        if pad > 0:\\n            h = x.get_shape().as_list()[1]\\n            if h % stride == 0:\\n                pad = pad * 2\\n            else:\\n                pad = max(kernel - (h % stride), 0)\\n\\n            pad_top = pad // 2\\n            pad_bottom = pad - pad_top\\n            pad_left = pad // 2\\n            pad_right = pad - pad_left\\n\\n            if pad_type == \\'zero\\':\\n                x = tf.pad(x, [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]])\\n            if pad_type == \\'reflect\\':\\n                x = tf.pad(x, [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], mode=\\'REFLECT\\')\\n\\n        if sn:\\n            w = tf.compat.v1.get_variable(\"kernel\", shape=[kernel, kernel, x.get_shape()[-1], channels], initializer=weight_init,\\n                                regularizer=weight_regularizer)\\n            x = Conv1D( filters=32, stride=1, padding=\\'VALID\\',kernel_size=kernel)(x)\\n            if use_bias:\\n                bias = tf.get_variable(\"bias\", [channels], initializer=tf.constant_initializer(0.0))\\n                x = tf.nn.bias_add(x, bias)\\n\\n        else:\\n            x = tf.compat.v1.layers.conv1d(inputs=x, filters=channels,\\n                                 kernel_size=kernel, kernel_initializer=weight_init,\\n                                 kernel_regularizer=weight_regularizer,\\n                                 stride=stride, use_bias=use_bias)\\n\\n        return x\\n\\ndef global_context_block(x, channels, use_bias=True, sn=False, scope=\\'gc_block\\'):\\n    with tf.compat.v1.variable_scope(scope):\\n        with tf.compat.v1.variable_scope(\\'context_modeling\\'):\\n            bs, h, w = x.get_shape().as_list()\\n            #c=1\\n            #x = tf.expand_dims(x, axis=-1)\\n            print(x.shape)\\n            input_x = x\\n            #input_x = hw_flatten(input_x)  # [N, H*W, C]\\n            input_x = tf.transpose(input_x, perm=[0, 2, 1])\\n            input_x = tf.expand_dims(input_x, axis=1)\\n\\n            context_mask = conv(x, channels=1, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\\'conv\\')\\n            context_mask = hw_flatten(context_mask)\\n            context_mask = tf.nn.softmax(context_mask, axis=1)  # [N, H*W, 1]\\n            context_mask = tf.transpose(context_mask, perm=[0, 2, 1])\\n            context_mask = tf.expand_dims(context_mask, axis=-1)\\n\\n            context = tf.matmul(input_x, context_mask)\\n            context = tf.reshape(context, shape=[bs, 1, 1, c])\\n\\n        with tf.variable_scope(\\'transform_0\\'):\\n            context_transform = conv(context, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\\'conv_0\\')\\n            context_transform = layer_norm(context_transform)\\n            context_transform = relu(context_transform)\\n            context_transform = conv(context_transform, channels=c, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\\'conv_1\\')\\n            context_transform = sigmoid(context_transform)\\n\\n            x = x * context_transform\\n\\n        with tf.variable_scope(\\'transform_1\\'):\\n            context_transform = conv(context, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\\'conv_0\\')\\n            context_transform = layer_norm(context_transform)\\n            context_transform = relu(context_transform)\\n            context_transform = conv(context_transform, channels=c, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope=\\'conv_1\\')\\n\\n            x = x + context_transform\\n\\n        return x\\n\\ndef layer_norm(x, scope=\\'layer_norm\\'):\\n    return tf.contrib.layers.layer_norm(x,\\n                                        center=True, scale=True,\\n                                        scope=scope)\\ndef relu(x):\\n    return tf.nn.relu(x)\\n\\ndef sigmoid(x):\\n    return tf.sigmoid(x)\\n\\ndef hw_flatten(x):\\n    return tf.reshape(x, shape=[x.shape[0], -1, x.shape[-1]])\\n\\ndef spectral_norm(w, iteration=1):\\n    w_shape = w.shape.as_list()\\n    w = tf.reshape(w, [-1, w_shape[-1]])\\n\\n    u = tf.compat.v1.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.random_normal_initializer(), trainable=False)\\n\\n    u_hat = u\\n    v_hat = None\\n    for i in range(iteration):\\n        \"\"\"\\n        power iteration\\n        Usually iteration = 1 will be enough\\n        \"\"\"\\n        v_ = tf.matmul(u_hat, tf.transpose(w))\\n        v_hat = tf.nn.l2_normalize(v_)\\n\\n        u_ = tf.matmul(v_hat, w)\\n        u_hat = tf.nn.l2_normalize(u_)\\n\\n    u_hat = tf.stop_gradient(u_hat)\\n    v_hat = tf.stop_gradient(v_hat)\\n\\n    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\\n\\n    with tf.control_dependencies([u.assign(u_hat)]):\\n        w_norm = w / sigma\\n        w_norm = tf.reshape(w_norm, w_shape)\\n\\n    return w_norm'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''####global context\n",
        "weight_init = tf.compat.v1.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
        "weight_regularizer = tf.keras.regularizers.L2(0.0001)\n",
        "\n",
        "def conv(x, channels, kernel=4, stride=2, pad=0, pad_type='zero', use_bias=True, sn=False, scope='conv_0'):\n",
        "    with tf.compat.v1.variable_scope(scope):\n",
        "        if pad > 0:\n",
        "            h = x.get_shape().as_list()[1]\n",
        "            if h % stride == 0:\n",
        "                pad = pad * 2\n",
        "            else:\n",
        "                pad = max(kernel - (h % stride), 0)\n",
        "\n",
        "            pad_top = pad // 2\n",
        "            pad_bottom = pad - pad_top\n",
        "            pad_left = pad // 2\n",
        "            pad_right = pad - pad_left\n",
        "\n",
        "            if pad_type == 'zero':\n",
        "                x = tf.pad(x, [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]])\n",
        "            if pad_type == 'reflect':\n",
        "                x = tf.pad(x, [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], mode='REFLECT')\n",
        "\n",
        "        if sn:\n",
        "            w = tf.compat.v1.get_variable(\"kernel\", shape=[kernel, kernel, x.get_shape()[-1], channels], initializer=weight_init,\n",
        "                                regularizer=weight_regularizer)\n",
        "            x = Conv1D( filters=32, stride=1, padding='VALID',kernel_size=kernel)(x)\n",
        "            if use_bias:\n",
        "                bias = tf.get_variable(\"bias\", [channels], initializer=tf.constant_initializer(0.0))\n",
        "                x = tf.nn.bias_add(x, bias)\n",
        "\n",
        "        else:\n",
        "            x = tf.compat.v1.layers.conv1d(inputs=x, filters=channels,\n",
        "                                 kernel_size=kernel, kernel_initializer=weight_init,\n",
        "                                 kernel_regularizer=weight_regularizer,\n",
        "                                 stride=stride, use_bias=use_bias)\n",
        "\n",
        "        return x\n",
        "\n",
        "def global_context_block(x, channels, use_bias=True, sn=False, scope='gc_block'):\n",
        "    with tf.compat.v1.variable_scope(scope):\n",
        "        with tf.compat.v1.variable_scope('context_modeling'):\n",
        "            bs, h, w = x.get_shape().as_list()\n",
        "            #c=1\n",
        "            #x = tf.expand_dims(x, axis=-1)\n",
        "            print(x.shape)\n",
        "            input_x = x\n",
        "            #input_x = hw_flatten(input_x)  # [N, H*W, C]\n",
        "            input_x = tf.transpose(input_x, perm=[0, 2, 1])\n",
        "            input_x = tf.expand_dims(input_x, axis=1)\n",
        "\n",
        "            context_mask = conv(x, channels=1, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope='conv')\n",
        "            context_mask = hw_flatten(context_mask)\n",
        "            context_mask = tf.nn.softmax(context_mask, axis=1)  # [N, H*W, 1]\n",
        "            context_mask = tf.transpose(context_mask, perm=[0, 2, 1])\n",
        "            context_mask = tf.expand_dims(context_mask, axis=-1)\n",
        "\n",
        "            context = tf.matmul(input_x, context_mask)\n",
        "            context = tf.reshape(context, shape=[bs, 1, 1, c])\n",
        "\n",
        "        with tf.variable_scope('transform_0'):\n",
        "            context_transform = conv(context, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope='conv_0')\n",
        "            context_transform = layer_norm(context_transform)\n",
        "            context_transform = relu(context_transform)\n",
        "            context_transform = conv(context_transform, channels=c, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope='conv_1')\n",
        "            context_transform = sigmoid(context_transform)\n",
        "\n",
        "            x = x * context_transform\n",
        "\n",
        "        with tf.variable_scope('transform_1'):\n",
        "            context_transform = conv(context, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope='conv_0')\n",
        "            context_transform = layer_norm(context_transform)\n",
        "            context_transform = relu(context_transform)\n",
        "            context_transform = conv(context_transform, channels=c, kernel=1, stride=1, use_bias=use_bias, sn=sn, scope='conv_1')\n",
        "\n",
        "            x = x + context_transform\n",
        "\n",
        "        return x\n",
        "\n",
        "def layer_norm(x, scope='layer_norm'):\n",
        "    return tf.contrib.layers.layer_norm(x,\n",
        "                                        center=True, scale=True,\n",
        "                                        scope=scope)\n",
        "def relu(x):\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return tf.sigmoid(x)\n",
        "\n",
        "def hw_flatten(x):\n",
        "    return tf.reshape(x, shape=[x.shape[0], -1, x.shape[-1]])\n",
        "\n",
        "def spectral_norm(w, iteration=1):\n",
        "    w_shape = w.shape.as_list()\n",
        "    w = tf.reshape(w, [-1, w_shape[-1]])\n",
        "\n",
        "    u = tf.compat.v1.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.random_normal_initializer(), trainable=False)\n",
        "\n",
        "    u_hat = u\n",
        "    v_hat = None\n",
        "    for i in range(iteration):\n",
        "        \"\"\"\n",
        "        power iteration\n",
        "        Usually iteration = 1 will be enough\n",
        "        \"\"\"\n",
        "        v_ = tf.matmul(u_hat, tf.transpose(w))\n",
        "        v_hat = tf.nn.l2_normalize(v_)\n",
        "\n",
        "        u_ = tf.matmul(v_hat, w)\n",
        "        u_hat = tf.nn.l2_normalize(u_)\n",
        "\n",
        "    u_hat = tf.stop_gradient(u_hat)\n",
        "    v_hat = tf.stop_gradient(v_hat)\n",
        "\n",
        "    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n",
        "\n",
        "    with tf.control_dependencies([u.assign(u_hat)]):\n",
        "        w_norm = w / sigma\n",
        "        w_norm = tf.reshape(w_norm, w_shape)\n",
        "\n",
        "    return w_norm'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mhCPuDx2dBC",
        "outputId": "b4ee5f70-077b-4b92-fef6-352f423647fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11 (None, None, 128)\n",
            "22 (None, None, 200)\n"
          ]
        }
      ],
      "source": [
        "### new experiment  GCN...............................................................\n",
        "# concatenating the word and character embedding outputs\n",
        "\n",
        "output = concatenate([words,pos, char, casing])  #without attention layer\n",
        "output = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\n",
        "\n",
        "filter_nums = 128\n",
        "output = tf.keras.Sequential([\n",
        "                    tf.keras.layers.Conv1D(filters=filter_nums, kernel_size=2, activation='relu',\n",
        "                                           padding='same', dilation_rate=1,kernel_regularizer='l2'),\n",
        "                    tf.keras.layers.Conv1D(filters=filter_nums, kernel_size=3, activation='relu',\n",
        "                                           padding='same', dilation_rate=1,kernel_regularizer='l2'),\n",
        "                    tf.keras.layers.Conv1D(filters=filter_nums, kernel_size=4, activation='relu',\n",
        "                                           padding='same', dilation_rate=2,kernel_regularizer='l2')])(output)\n",
        "\n",
        "\n",
        "output = Attention(use_scale=True)([output,output]) #SELF-ATTENTION LAYER\n",
        "output=Dropout(0.2)(output)\n",
        "\n",
        "output = Bidirectional(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.25))(output)\n",
        "\n",
        "output = Attention(use_scale=True)([output,output]) #SELF-ATTENTION LAYER\n",
        "output=Dropout(0.2)(output)\n",
        "\n",
        "# fully connected DNN layer\n",
        "output = TimeDistributed(Dense(100, activation = 'relu')) (output)\n",
        "output=Dropout(0.2)(output)\n",
        "# output layer\n",
        "#output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
        "output = TimeDistributed(Dense(len(label2Idx)))(output)\n",
        "\n",
        "\n",
        "#from crf import CRF\n",
        "crf_ = CRF(len(label2Idx))\n",
        "output = crf_(output)\n",
        "\n",
        "model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor=\"val_loss\", patience = 3)\n",
        "#reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, min_lr=0.0001)\n",
        "#opt=tf.keras.optimizers.Nadam(learning_rate=0.00001)\n",
        "#opt=tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "#opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "opt=tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "#model.compile(optimizer=Adam(learning_rate=0.001), loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "#model.compile(optimizer='rmsprop', loss=crf_.loss, metrics=[crf_.accuracy])\n",
        "\n",
        "#model = Model(inputs=[words_input, pos_input, casing_input,character_input], outputs=[output])\n",
        "#model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(learning_rate=0.001))\n",
        "#model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyg-tCnjLm18",
        "outputId": "dbb4b067-408c-475f-defe-4ee9cc14b699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " char_input (InputLayer)     [(None, None, 52)]           0         []                            \n",
            "                                                                                                  \n",
            " char_embedding (TimeDistri  (None, None, 52, 100)        11100     ['char_input[0][0]']          \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, None, 52, 33)         13233     ['char_embedding[0][0]']      \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDi  (None, None, 52, 33)         3300      ['time_distributed[0][0]']    \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDi  (None, None, 52, 34)         3400      ['time_distributed_1[0][0]']  \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, None, 52, 100)        0         ['time_distributed[0][0]',    \n",
            "                                                                     'time_distributed_1[0][0]',  \n",
            "                                                                     'time_distributed_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, None, 52, 100)        0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDi  (None, None, 1, 100)         0         ['dropout[0][0]']             \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " time_distributed_4 (TimeDi  (None, None, 100)            0         ['time_distributed_3[0][0]']  \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " words_input (InputLayer)    [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " pos_input (InputLayer)      [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " time_distributed_5 (TimeDi  (None, None, 100)            0         ['time_distributed_4[0][0]']  \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " casing_input (InputLayer)   [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 100)            1285300   ['words_input[0][0]']         \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, None, 100)            1920500   ['pos_input[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 100)            0         ['time_distributed_5[0][0]']  \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, None, 8)              64        ['casing_input[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, None, 308)            0         ['embedding_1[0][0]',         \n",
            " )                                                                   'embedding_3[0][0]',         \n",
            "                                                                     'dropout_1[0][0]',           \n",
            "                                                                     'embedding_2[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, None, 200)            327200    ['concatenate_1[0][0]']       \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, None, 128)            166272    ['bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " attention (Attention)       (None, None, 128)            1         ['sequential[0][0]',          \n",
            "                                                                     'sequential[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, None, 128)            0         ['attention[0][0]']           \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, None, 200)            183200    ['dropout_2[0][0]']           \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " attention_1 (Attention)     (None, None, 200)            1         ['bidirectional_1[0][0]',     \n",
            "                                                                     'bidirectional_1[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, None, 200)            0         ['attention_1[0][0]']         \n",
            "                                                                                                  \n",
            " time_distributed_6 (TimeDi  (None, None, 100)            20100     ['dropout_3[0][0]']           \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, None, 100)            0         ['time_distributed_6[0][0]']  \n",
            "                                                                                                  \n",
            " time_distributed_7 (TimeDi  (None, None, 29)             2929      ['dropout_4[0][0]']           \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " crf (CRF)                   (None, None, 29)             841       ['time_distributed_7[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3937441 (15.02 MB)\n",
            "Trainable params: 731577 (2.79 MB)\n",
            "Non-trainable params: 3205864 (12.23 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PXLt0rHIbQe1"
      },
      "outputs": [],
      "source": [
        "#tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jXxu3G_aWfNx"
      },
      "outputs": [],
      "source": [
        "#from keras.callbacks import CSVLogger\n",
        "\n",
        "#csv_logger = CSVLogger(\"model_history_log.csv\", append=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DTvpFNFSKtu2"
      },
      "outputs": [],
      "source": [
        "#Train the model\n",
        "epochs = 20\n",
        "\n",
        "train_acc_average = []\n",
        "train_loss_average = []\n",
        "\n",
        "valid_acc_average = []\n",
        "valid_loss_average = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"Epoch %d/%d\"%(epoch,epochs))\n",
        "    a = Progbar(len(train_batch_len))\n",
        "    #b = Progbar(len(valid_batch_len))\n",
        "    train_acc = []\n",
        "    train_loss = []\n",
        "    valid_acc = []\n",
        "    valid_loss = []\n",
        "    for i,batch in enumerate(iterate_minibatches(train_batch,train_batch_len)):\n",
        "        labels, tokens, pos, casing,char = batch\n",
        "        if(len(labels)>1):\n",
        "          history = model.fit([tokens,pos, casing,char], labels, validation_split=0.1, callbacks=[early_stopping],verbose=1,use_multiprocessing=True)\n",
        "          #history = model.fit([tokens,char], labels, validation_split=0.1, callbacks=[early_stopping],verbose=1, use_multiprocessing=True)\n",
        "\n",
        "        #model.train_on_batch([tokens,pos, casing,char], labels)\n",
        "        #train_acc.append(acc)\n",
        "        #train_loss.append(loss)\n",
        "        a.update(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dHkrkv5BtdMi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "#Method to compute the accruarcy. Call predict_labels to get the labels for the dataset\n",
        "def compute_f1(predictions, correct, idx2Label):\n",
        "    label_pred = []\n",
        "    for sentence in predictions:\n",
        "        label_pred.append([idx2Label[element] for element in sentence])\n",
        "\n",
        "    label_correct = []\n",
        "    for sentence in correct:\n",
        "        label_correct.append([idx2Label[element] for element in sentence])\n",
        "\n",
        "\n",
        "    #print label_pred\n",
        "    #print label_correct\n",
        "\n",
        "    acc = sum(1 for (a, b) in zip(label_correct, label_pred) if a== b) /len(label_correct)\n",
        "    prec = compute_precision(label_pred, label_correct)\n",
        "    rec = compute_precision(label_correct, label_pred)\n",
        "\n",
        "    f1 = 0\n",
        "    if (rec+prec) > 0:\n",
        "        f1 = 2.0 * prec * rec / (prec + rec);\n",
        "\n",
        "    return prec, rec, acc, f1\n",
        "\n",
        "def compute_precision(guessed_sentences, correct_sentences):\n",
        "    assert(len(guessed_sentences) == len(correct_sentences))\n",
        "    correctCount = 0\n",
        "    count = 0\n",
        "\n",
        "\n",
        "    for sentenceIdx in range(len(guessed_sentences)):\n",
        "        guessed = guessed_sentences[sentenceIdx]\n",
        "        correct = correct_sentences[sentenceIdx]\n",
        "        assert(len(guessed) == len(correct))\n",
        "        idx = 0\n",
        "        while idx < len(guessed):\n",
        "            if guessed[idx][0] == 'B': #A new chunk starts\n",
        "                count += 1\n",
        "\n",
        "                if guessed[idx] == correct[idx]:\n",
        "                    idx += 1\n",
        "                    correctlyFound = True\n",
        "\n",
        "                    while idx < len(guessed) and guessed[idx][0] == 'I': #Scan until it no longer starts with I\n",
        "                        if guessed[idx] != correct[idx]:\n",
        "                            correctlyFound = False\n",
        "\n",
        "                        idx += 1\n",
        "\n",
        "                    if idx < len(guessed):\n",
        "                        if correct[idx][0] == 'I': #The chunk in correct was longer\n",
        "                            correctlyFound = False\n",
        "\n",
        "\n",
        "                    if correctlyFound:\n",
        "                        correctCount += 1\n",
        "                else:\n",
        "                    idx += 1\n",
        "            else:\n",
        "                idx += 1\n",
        "\n",
        "    precision = 0\n",
        "    if count > 0:\n",
        "        precision = float(correctCount) / count\n",
        "\n",
        "    return precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Akq7IzZN-Tow"
      },
      "outputs": [],
      "source": [
        "#tf.keras.backend.set_learning_phase(False)\n",
        "def Return_list(pred,labels):\n",
        "  label_=[]\n",
        "  for sentence in labels:\n",
        "   label_.append(sentence.flatten().argmax(axis=-1))\n",
        "\n",
        "  #print(len(label_[0]))\n",
        "  pred = pred.argmax(axis=-1)\n",
        "  #l = labels.argmax(axis=1)\n",
        "\n",
        "  return list(pred),label_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0ZFf9GHWUAFx"
      },
      "outputs": [],
      "source": [
        "# Use the following prediction function when the labels are using numbers\n",
        "def tag_dataset(dataset):\n",
        "    correctLabels = []\n",
        "    predLabels = []\n",
        "    b = Progbar(len(dataset))\n",
        "    for i,data in enumerate(dataset):\n",
        "        tokens, pos, casing,char, labels = data\n",
        "        tokens = np.asarray([tokens])\n",
        "        pos=np.asarray([pos])\n",
        "        casing = np.asarray([casing])\n",
        "        char = np.asarray([char])\n",
        "        pred = model.predict([tokens,pos, casing,char], verbose=False)[0]\n",
        "        pred = pred.argmax(axis=-1) #Predict the classes\n",
        "        correctLabels.append(labels)\n",
        "        predLabels.append(pred)\n",
        "        b.update(i)\n",
        "    b.update(i+1)\n",
        "    return predLabels, correctLabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Eg-S7rvyTMeY"
      },
      "outputs": [],
      "source": [
        "# Use the following prediction function when the labels are using the one hot encoding technique\n",
        "def tag_dataset_(dataset):\n",
        "    correctLabels = []\n",
        "    predLabels = []\n",
        "    b = Progbar(len(dataset))\n",
        "    for i,batch in enumerate(dataset):\n",
        "        tokens, pos, casing,char, labels = batch\n",
        "\n",
        "        tokens = np.asarray([tokens])\n",
        "        pos=np.asarray([pos])\n",
        "        casing = np.asarray([casing])\n",
        "        char = np.asarray([char])\n",
        "\n",
        "        pred = model.predict([tokens,pos, casing,char], verbose=False)[0]\n",
        "\n",
        "        pred,label=Return_list(pred,labels)\n",
        "\n",
        "        correctLabels.append(label)\n",
        "        predLabels.append(pred)\n",
        "\n",
        "        b.update(i)\n",
        "    b.update(i+1)\n",
        "    return predLabels, correctLabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1RohfjHyMsvf"
      },
      "outputs": [],
      "source": [
        "#model.save(\"biLSTM_attention_crf_2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dylOaNSu2mGp"
      },
      "outputs": [],
      "source": [
        "#   Performance on test dataset\n",
        "#model = load_model (\"models/biLSTM_attention.h5\")\n",
        "#tf.keras.backend.set_learning_phase(False)\n",
        "predLabels, correctLabels = tag_dataset_(test_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8xneBIEZjnxe"
      },
      "outputs": [],
      "source": [
        "pre_test, rec_test, acc_test, f1_test= compute_f1(predLabels, correctLabels, idx2Label)\n",
        "#print(pre_test, rec_test, f1_test)\n",
        "print(\"Test-Data: Prec: %.3f, Rec: %.3f, Acc: %.3f, F1: %.3f\" % (pre_test, rec_test, acc_test, f1_test))\n",
        "\n",
        "# save correct labels & prediected labels\n",
        "with open ('correct.txt', 'w') as p:\n",
        "\tp.write(str(correctLabels))\n",
        "\n",
        "with open ('pred_biLSTM_attn.txt', 'w') as fp:\n",
        "\tfp.write(str(predLabels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DEprlvTvkgQd"
      },
      "outputs": [],
      "source": [
        "## convert multidimentional arrays to one list for all words\n",
        "#l = [arr.tolist() for arr in predLabels]\n",
        "#c = [b.tolist() for b in correctLabels]\n",
        "import itertools\n",
        "\n",
        "p_l=list(itertools.chain.from_iterable(predLabels))\n",
        "c_l=list(itertools.chain.from_iterable(correctLabels))\n",
        "\n",
        "#from sklearn.metrics import multilabel_confusion_matrix\n",
        "#multilabel_confusion_matrix(p_l, c_l)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(c_l, p_l))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aaVSx2KidPr1"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "plt.figure(figsize=(30,20))\n",
        "fx=sns.heatmap(confusion_matrix(c_l,p_l), annot=True, fmt=\".2f\",cmap=\"GnBu\")\n",
        "fx.set_title('Confusion Matrix \\n');\n",
        "fx.set_xlabel('\\n Predicted Values\\n')\n",
        "fx.set_ylabel('Actual Values\\n');\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QgSfikWxgsYM"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# confusion\n",
        "def plot_confusion_matrix(predLabels, correctLabels, idx2Label):\n",
        "  conf_mat = confusion_matrix(predLabels, correctLabels)\n",
        "  plt.subplots(figsize=(10, 10))\n",
        "  sns.heatmap(conf_mat,annot=True,xticklabels=idx2Label.Type.values,yticklabels=idx2Label.Type.values)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "res = ax.imshow(array(conf_mat), cmap=cm.jet, interpolation='nearest')\n",
        "cb = fig.colorbar(res)\n",
        "savefig(\"confmat.png\", format=\"png\")\n",
        "'''\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}